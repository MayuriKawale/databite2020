{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO0nL2OmcGkO"
      },
      "source": [
        "***Feature Extraction:***\n",
        "  \n",
        "  1. Bag of Words\n",
        "  2. TFIDF vectorizer\n",
        "  3. Word2Vec\n",
        "\n",
        "**In this section we will talk about feature extraction examples of text data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_59y8f8c7Sq"
      },
      "source": [
        "# required imports\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tYSBYNqdDBL"
      },
      "source": [
        "# First lines from novel 'Tale of two cities' by Charles Dickens\n",
        "# Source: The Project Gutenberg\n",
        "tale_of_cities = ['it was the best of times',\n",
        "                  'it was the worst of times',\n",
        "                  'it was the age of wisdom',\n",
        "                  'it was the age of foolishness',\n",
        "                  'it was the epoch of belief'  \n",
        "                  ]\n",
        "\n",
        "# Convert a collection of text documents to a matrix of number of features\n",
        "vectorizer = CountVectorizer()\n",
        "features = vectorizer.fit_transform(tale_of_cities)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDj1aG9kdbJh",
        "outputId": "0e7f74eb-a04a-4438-a6b9-cfb3591ccd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Printing the identified Unique words along with their indices \n",
        "print(\"Vocabulary: \", vectorizer.vocabulary_)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary:  {'it': 5, 'was': 9, 'the': 7, 'best': 2, 'of': 6, 'times': 8, 'worst': 11, 'age': 0, 'wisdom': 10, 'foolishness': 4, 'epoch': 3, 'belief': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y_PBbRtdeEI",
        "outputId": "26ce82f8-1547-4736-83a3-6998d5728bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print('The feature names: ', vectorizer.get_feature_names())\n",
        "print('Number of features: ', len(vectorizer.get_feature_names()))\n",
        "print('The vectorized text (Encoded): ')\n",
        "print(features.toarray())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The feature names:  ['age', 'belief', 'best', 'epoch', 'foolishness', 'it', 'of', 'the', 'times', 'was', 'wisdom', 'worst']\n",
            "Number of features:  12\n",
            "The vectorized text (Encoded): \n",
            "[[0 0 1 0 0 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 1 1 1 1 1 0 1]\n",
            " [1 0 0 0 0 1 1 1 0 1 1 0]\n",
            " [1 0 0 0 1 1 1 1 0 1 0 0]\n",
            " [0 1 0 1 0 1 1 1 0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To_nuW9ll9u3"
      },
      "source": [
        "tale_of_cities = ['it was the best of times',\n",
        "                  'it was the worst of times',\n",
        "                  'it was the age of wisdom',\n",
        "                  'it was the age of foolishness',\n",
        "                  'it was the epoch of belief'  \n",
        "                  ]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkZ9iut9dgiH",
        "outputId": "5bde1f19-eabd-46b0-de63-e44b164d0752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(tale_of_cities)\n",
        "print(tfidf_vectorizer.get_feature_names())\n",
        "print(tfidf_features.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['age', 'belief', 'best', 'epoch', 'foolishness', 'it', 'of', 'the', 'times', 'was', 'wisdom', 'worst']\n",
            "(5, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoWZFwv1luic",
        "outputId": "214aef20-0a3d-4226-8849-887d8717420a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "print('The feature names: ', tfidf_vectorizer.get_feature_names())\n",
        "print('Number of features: ', len(tfidf_vectorizer.get_feature_names()))\n",
        "print('The vectorized text (Encoded): ')\n",
        "print(tfidf_features.toarray())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The feature names:  ['age', 'belief', 'best', 'epoch', 'foolishness', 'it', 'of', 'the', 'times', 'was', 'wisdom', 'worst']\n",
            "Number of features:  12\n",
            "The vectorized text (Encoded): \n",
            "[[0.         0.         0.62510433 0.         0.         0.29786556\n",
            "  0.29786556 0.29786556 0.50433024 0.29786556 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.29786556\n",
            "  0.29786556 0.29786556 0.50433024 0.29786556 0.         0.62510433]\n",
            " [0.50433024 0.         0.         0.         0.         0.29786556\n",
            "  0.29786556 0.29786556 0.         0.29786556 0.62510433 0.        ]\n",
            " [0.50433024 0.         0.         0.         0.62510433 0.29786556\n",
            "  0.29786556 0.29786556 0.         0.29786556 0.         0.        ]\n",
            " [0.         0.5863888  0.         0.5863888  0.         0.27941741\n",
            "  0.27941741 0.27941741 0.         0.27941741 0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3Hkvr7yoGAu"
      },
      "source": [
        "**Word2Vec embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUN9CvqvuNOV",
        "outputId": "3265fb36-5ade-4fa9-954e-5e8f726c87f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# common texts data from gensim library.\n",
        "common_texts"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['human', 'interface', 'computer'],\n",
              " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
              " ['eps', 'user', 'interface', 'system'],\n",
              " ['system', 'human', 'system', 'eps'],\n",
              " ['user', 'response', 'time'],\n",
              " ['trees'],\n",
              " ['graph', 'trees'],\n",
              " ['graph', 'minors', 'trees'],\n",
              " ['graph', 'minors', 'survey']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7TKgJacuQls",
        "outputId": "6389729b-26fb-4cea-8f9d-6dcc688d2ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Word2Vec model \n",
        "model = Word2Vec(common_texts, size=100, window=5, min_count=1)\n",
        "\n",
        "# Vector for a specific word, for ex: human \n",
        "model.wv[\"human\"]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.43388971e-03, -3.61608784e-03,  4.48620087e-03, -4.94819973e-03,\n",
              "       -8.77382117e-04,  2.89989356e-03,  1.67383300e-03,  3.65505158e-03,\n",
              "        1.05970865e-03, -1.77398499e-03, -3.17351150e-05, -1.00901467e-03,\n",
              "       -4.70360555e-03,  2.45962106e-03, -8.47141142e-04,  4.22295090e-03,\n",
              "       -3.32458131e-03, -2.70062871e-03,  3.02404957e-03, -2.85309227e-03,\n",
              "        4.08883300e-03, -2.22729053e-03, -1.20713876e-03,  2.73951446e-03,\n",
              "        7.23199802e-04, -2.36160099e-03, -4.77821007e-03, -1.00123005e-04,\n",
              "       -1.68618335e-05,  2.86461227e-03,  2.54028972e-04, -2.92142574e-03,\n",
              "       -9.71496222e-04, -3.78758716e-03, -9.86306812e-04, -1.51610945e-03,\n",
              "       -1.18273031e-03, -2.92744080e-04,  9.44134837e-04, -2.54136883e-03,\n",
              "       -1.26092217e-03,  1.43130543e-03, -3.20353522e-03, -4.49500978e-03,\n",
              "        3.64622171e-03,  2.72988564e-05, -1.49934110e-03,  4.62230807e-03,\n",
              "        4.85059991e-03,  4.40129777e-04,  3.59853124e-03, -3.15364194e-03,\n",
              "       -1.91330467e-03, -5.53277379e-04,  1.65164506e-03,  6.27720074e-05,\n",
              "       -2.98797362e-03, -6.42290630e-04,  3.71668627e-03, -4.35603037e-03,\n",
              "        1.00936182e-03,  2.28845817e-03,  1.80768722e-03,  4.07730974e-03,\n",
              "        3.09156813e-03,  8.77152313e-04,  2.53100833e-03, -4.28344542e-03,\n",
              "       -1.51691737e-03,  2.66025052e-03,  1.28011941e-03, -3.37277353e-03,\n",
              "       -1.01960868e-04, -2.04460905e-03, -3.25225457e-03, -4.28004097e-03,\n",
              "       -1.53078581e-03, -2.63293949e-03, -1.08569526e-04, -3.99666053e-04,\n",
              "        3.85802152e-04,  5.08119643e-04, -7.15099566e-04, -4.96340776e-03,\n",
              "        1.00005092e-03, -8.89814910e-05, -2.08002911e-03,  5.27428172e-04,\n",
              "       -1.77859829e-03,  4.47132858e-03,  3.66507401e-03,  4.71695419e-03,\n",
              "       -6.31370873e-04, -2.52041500e-03, -6.15645491e-04, -3.49082984e-03,\n",
              "       -4.72053653e-03, -2.61600316e-03, -1.42989797e-03,  1.75715575e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI-Bk_DXudHO",
        "outputId": "b57613e9-3a9c-4921-b063-daa20d0995f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Calculate the most similar words to human\n",
        "model.wv.most_similar(\"human\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('response', 0.08395902812480927),\n",
              " ('graph', 0.07479733973741531),\n",
              " ('time', 0.06893133372068405),\n",
              " ('survey', 0.04686649888753891),\n",
              " ('system', 0.031810905784368515),\n",
              " ('computer', 0.020856063812971115),\n",
              " ('minors', -0.02121073007583618),\n",
              " ('eps', -0.06385811418294907),\n",
              " ('user', -0.07140786200761795),\n",
              " ('interface', -0.07448561489582062)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7XpH28TmB2W",
        "outputId": "4f1ee280-9203-40ac-e877-50fb3a7bda01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# define training data\n",
        "corpus = ['it was the best of times',\n",
        "            'it was the worst of times',\n",
        "            'it was the age of wisdom',\n",
        "            'it was the age of foolishness',\n",
        "            'it was the epoch of belief']\n",
        "\n",
        "sentences = list() \n",
        "for sen in corpus:\n",
        "  x = nlp(sen)\n",
        "  y = list()\n",
        "  for token in x:\n",
        "    y.append(token.text)\n",
        "  sentences.append(y)\n",
        "\n",
        "print(sentences)\n",
        "\n",
        "# train model\n",
        "model = Word2Vec(sentences, min_count=1)\n",
        "# summarize the loaded model\n",
        "print(model)\n",
        "# summarize vocabulary\n",
        "words = list(model.wv.vocab)\n",
        "print(words)\n",
        "\n",
        "# access vector for one word\n",
        "print('Vector for a word in one of the sentences')\n",
        "print(model['wisdom'])\n",
        "# save model\n",
        "model.save('model.bin')\n",
        "# load model\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "print(new_model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['it', 'was', 'the', 'best', 'of', 'times'], ['it', 'was', 'the', 'worst', 'of', 'times'], ['it', 'was', 'the', 'age', 'of', 'wisdom'], ['it', 'was', 'the', 'age', 'of', 'foolishness'], ['it', 'was', 'the', 'epoch', 'of', 'belief']]\n",
            "Word2Vec(vocab=12, size=100, alpha=0.025)\n",
            "['it', 'was', 'the', 'best', 'of', 'times', 'worst', 'age', 'wisdom', 'foolishness', 'epoch', 'belief']\n",
            "vector for a word in one of the sentences\n",
            "[ 9.1444037e-04  7.7333819e-04  5.2312732e-04  1.0214958e-05\n",
            " -4.7556385e-03 -2.6045598e-03 -1.1960843e-03 -3.4238556e-03\n",
            " -1.9484337e-03 -3.6921909e-03 -4.5418143e-03  2.5264039e-03\n",
            " -4.0701227e-03 -2.7972648e-03  4.1562091e-03 -8.6244848e-04\n",
            "  4.1778055e-03 -2.9510350e-04 -4.5203120e-03 -2.7840114e-03\n",
            "  1.0026008e-03  1.8192318e-03  1.6008198e-04  4.8879418e-03\n",
            "  2.7620923e-04  3.5321589e-03 -4.2924713e-03 -4.3855542e-03\n",
            " -4.5332210e-03  3.5528119e-03 -3.8095668e-03 -6.3364644e-04\n",
            " -1.8129537e-03  4.3134266e-03  4.3559084e-03  2.7797751e-03\n",
            "  4.5660986e-03  3.6586011e-03  2.8703634e-03 -1.8829925e-03\n",
            "  3.1977729e-03  3.1848261e-03 -1.2637614e-03  8.0671639e-04\n",
            "  3.4796944e-04 -1.5880713e-03  3.5944229e-03  4.1696592e-03\n",
            " -3.8119669e-03 -1.0107806e-03  3.3900603e-03 -3.3568505e-03\n",
            "  1.7896196e-04  2.3063240e-04 -4.4614361e-03  4.2780056e-03\n",
            " -4.3758708e-03 -2.0967198e-03 -4.1210647e-03 -1.9974539e-03\n",
            " -4.1284095e-03 -1.9397198e-03  2.5330919e-03 -2.3919654e-03\n",
            " -4.1962471e-03  3.2287524e-05  5.9649895e-04  1.2822738e-03\n",
            " -1.9733631e-03  1.7301536e-03  5.2965980e-04  4.2531774e-03\n",
            "  1.5557879e-03 -4.8516537e-03 -6.1441091e-04 -1.3637531e-03\n",
            " -2.3719267e-04  3.9045147e-03 -4.4202306e-03 -8.5380970e-04\n",
            "  4.9707950e-03  2.3204577e-03 -3.4009656e-03  2.8073513e-03\n",
            "  1.0493407e-03 -1.4195838e-03 -3.1903582e-03  2.2596938e-03\n",
            "  1.4922351e-03  3.4054427e-03  2.9656061e-03 -3.7653309e-03\n",
            "  3.7496546e-03 -7.2461838e-04 -3.6047124e-03 -2.1219624e-03\n",
            " -8.2999456e-04 -1.0896674e-04 -1.5415087e-03 -3.3720753e-03]\n",
            "Word2Vec(vocab=12, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyew38oGpQmd",
        "outputId": "b71167c9-1cec-405c-8281-92bd1b3a1a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KAIaAqZq9cA",
        "outputId": "71f08d6b-a5c1-4cee-97a3-1f561ef6bdeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = list(model.wv.vocab)\n",
        "print(words)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['it', 'was', 'the', 'best', 'of', 'times', 'worst', 'age', 'wisdom', 'foolishness', 'epoch', 'belief']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b145Oz0rFxU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}